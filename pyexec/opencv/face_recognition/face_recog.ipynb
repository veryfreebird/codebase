{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "face/eyes detection\n",
    "抓脸\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "face_cascade = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv.CascadeClassifier('haarcascade_eye_tree_eyeglasses.xml')\n",
    "cap = cv.VideoCapture(0)\n",
    "num = 0\n",
    "\n",
    "while(True):\n",
    "    # 一帧一帧捕捉\n",
    "    ret, frame = cap.read()\n",
    "    # 我们对帧的操作在这里\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        eyes_found = False\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray,1.1,2)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            if not eyes_found: \n",
    "                eyes_found = True\n",
    "                face_img = frame[y-10:y+h+10, x-10:x+w+10]\n",
    "                image_name = './james/%d.jpg' % (num)\n",
    "                cv.imwrite(image_name,face_img)\n",
    "                num += 1\n",
    "                cv.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "            cv.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "    cv.imshow('img',frame)\n",
    "    if cv.waitKey(2) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "训练\n",
    "'''\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#脸部检测函数\n",
    "def face_detect_demo(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    face_detector = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "    faces = face_detector.detectMultiScale(gray, 1.2, 6)\n",
    "    # 如果未检测到面部，则返回原始图像\n",
    "    if (len(faces) == 0):\n",
    "        return None, None\n",
    "    # 目前假设只有一张脸，xy为左上角坐标，wh为矩形的宽高\n",
    "    (x, y, w, h) = faces[0]\n",
    "    # 返回图像的脸部部分\n",
    "    return gray[y:y + w, x:x + h], faces[0]\n",
    "\n",
    "def ReFileName(dirPath):\n",
    "    \"\"\"\n",
    "    :param dirPath: 文件夹路径\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 对目录下的文件进行遍历\n",
    "    faces=[]\n",
    "    for file in os.listdir(dirPath):\n",
    "        # 判断是否是文件\n",
    "        if os.path.isfile(os.path.join(dirPath, file)) == True:\n",
    "           c= os.path.basename(file)\n",
    "           name = dirPath + '\\\\' + c\n",
    "           img = cv2.imread(name)\n",
    "           # 检测脸部\n",
    "           face, rect = face_detect_demo(img)\n",
    "           # 我们忽略未检测到的脸部\n",
    "           if face is not None:\n",
    "               # 将脸添加到脸部列表并添加相应的标签\n",
    "               faces.append(face)\n",
    "    cv2.waitKey(1)\n",
    "    cv2.destroyAllWindows()\n",
    "    return faces\n",
    "\n",
    "#David\n",
    "dirDavid = r\"C:\\james_home\\local_src\\codebase\\pyexec\\opencv\\face_recognition\\david\"#文件路径\n",
    "Davidfaces=ReFileName(dirDavid)#调用函数\n",
    "labelDavidfaces=np.array([0 for i in range(len(Davidfaces))])#标签处理\n",
    "\n",
    "#Ning\n",
    "dirNing = r\"C:\\james_home\\local_src\\codebase\\pyexec\\opencv\\face_recognition\\ning\"#文件路径\n",
    "Ningfaces=ReFileName(dirNing)#调用函数\n",
    "labelNingfaces=np.array([1 for i in range(len(Ningfaces))])#标签处理\n",
    "\n",
    "#Jamesfaces\n",
    "dirMyfaces = r\"C:\\james_home\\local_src\\codebase\\pyexec\\opencv\\face_recognition\\james\"#文件路径\n",
    "Jamesfaces=ReFileName(dirMyfaces)#调用函数\n",
    "labelJamesfaces=np.array([2 for i in range(len(Jamesfaces))])#标签处理\n",
    "\n",
    "#Jingfaces\n",
    "dirJing = r\"C:\\james_home\\local_src\\codebase\\pyexec\\opencv\\face_recognition\\jingjing\"#文件路径\n",
    "Jingfaces=ReFileName(dirJing)#调用函数\n",
    "labelJingfaces=np.array([3 for i in range(len(Jingfaces))])#标签处理\n",
    "\n",
    "#Rosefaces\n",
    "dirRose = r\"C:\\james_home\\local_src\\codebase\\pyexec\\opencv\\face_recognition\\rose\"#文件路径\n",
    "Rosefaces=ReFileName(dirRose)#调用函数\n",
    "labelRosefaces=np.array([4 for i in range(len(Rosefaces))])#标签处理\n",
    "\n",
    "#拼接并打乱数据特征和标签\n",
    "x=np.concatenate((Jamesfaces,Davidfaces,Ningfaces,Jingfaces, Rosefaces),axis=0)\n",
    "y=np.concatenate((labelJamesfaces,labelDavidfaces,labelNingfaces,labelJingfaces, labelRosefaces),axis=0)\n",
    "\n",
    "index = [i for i in range(len(y))] # test_data为测试数据\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(index) # 打乱索引\n",
    "train_data = x[index]\n",
    "train_label = y[index]\n",
    "\n",
    "#分类器\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.train(train_data, train_label)\n",
    "# 保存训练数据\n",
    "recognizer.write('train.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "预测\n",
    "'''\n",
    "import cv2\n",
    "#人脸检测函数\n",
    "def face_detect_demo(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    face_detector = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "    eye_cascade = cv2.CascadeClassifier('haarcascade_eye_tree_eyeglasses.xml')\n",
    "    faces = face_detector.detectMultiScale(gray, 1.2, 6)\n",
    "    # 如果未检测到面部，则返回原始图像\n",
    "    if (len(faces) == 0):\n",
    "        return None, None\n",
    "    # 目前假设只有一张脸，xy为左上角坐标，wh为矩形的宽高\n",
    "    (x, y, w, h) = faces[0]\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray,1.1,2)\n",
    "    if (len(eyes) == 0):\n",
    "        return None, None \n",
    "    # 返回图像的脸部部分\n",
    "    return gray[y:y + w, x:x + h], faces[0]\n",
    "\n",
    "# 根据给定的人脸（x，y）坐标和宽度高度在图像上绘制矩形\n",
    "def draw_rectangle(img, rect):\n",
    "    (x, y, w, h) = rect#矩形框\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (255, 255, 0), 2)\n",
    "\n",
    "# 根据给定的人脸（x，y）坐标写出人名\n",
    "def draw_text(img, text, x, y):\n",
    "    cv2.putText(img, text, (x, y), cv2.FONT_HERSHEY_COMPLEX, 1, (128, 128, 0), 2)\n",
    "\n",
    "# 此函数识别图像中的人物并在脸部周围绘制一个矩形及其人名\n",
    "facelabel = [\"David\", \"Ning\", \"MaYun\", \"MaJingJing\", \"Rose\"]#人物名\n",
    "\n",
    "#导入训练结果\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read('train.yml')#读取前文训练的结果\n",
    "\n",
    "def predict(image):\n",
    " \n",
    "    # 检测人脸区域\n",
    "    face, rect = face_detect_demo(image)#face_detect_demo前面的人脸检测函数\n",
    "    #print(rect)=[x,y,w,h]\n",
    "    # 预测人脸名字\n",
    "    if not face is None:\n",
    "        label = recognizer.predict(face)\n",
    "        print(label)#label[0]为名字，label[1]可信度数值越低，可信度越高（\n",
    "        if label[1]<=70:\n",
    "            # 获取由人脸识别器返回的相应标签的人名\n",
    "            label_text = facelabel[label[0]]\n",
    "\n",
    "            # 在检测到的脸部周围画一个矩形\n",
    "            draw_rectangle(image, rect)\n",
    "            # 标出预测的人名\n",
    "            draw_text(image, label_text, rect[0], rect[1])\n",
    "            # 返回预测的图像\n",
    "            return image\n",
    "        else:\n",
    "            # 在检测到的脸部周围画一个矩形\n",
    "            draw_rectangle(image, rect)\n",
    "            # 标出预测的人名\n",
    "            draw_text(image, \"not find\", rect[0], rect[1])\n",
    "            # 返回预测的图像\n",
    "            return image\n",
    "    else:\n",
    "        return image\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # 一帧一帧捕捉\n",
    "    ret, frame = cap.read()\n",
    "    # 我们对帧的操作在这里\n",
    "    pred_img = predict(frame)\n",
    "    cv2.imshow('img',pred_img)\n",
    "    if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "dlib test\n",
    "面部标记识别\n",
    "https://blog.csdn.net/qq_19707521/article/details/80366524\n",
    "'''\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import cv2\n",
    "import dlib\n",
    "import imutils\n",
    " \n",
    "# 定义一个映射面部索引的字典\n",
    "# 特定人脸区域的地标\n",
    "FACIAL_LANDMARKS_IDXS = OrderedDict([\n",
    "\t(\"mouth\", (48, 68)),\n",
    "\t(\"right_eyebrow\", (17, 22)),\n",
    "\t(\"left_eyebrow\", (22, 27)),\n",
    "\t(\"right_eye\", (36, 42)),\n",
    "\t(\"left_eye\", (42, 48)),\n",
    "\t(\"nose\", (27, 36)),\n",
    "\t(\"jaw\", (0, 17))\n",
    "])\n",
    " \n",
    "def rect_to_bb(rect):\n",
    "        # 由DLIB预测一个边界并转换它\n",
    "        # 对于通常我们所做的格式（x，y，w，h）\n",
    "        # OPEN与OpenCV\n",
    "\tx = rect.left()\n",
    "\ty = rect.top()\n",
    "\tw = rect.right() - x\n",
    "\th = rect.bottom() - y\n",
    " \n",
    "\t# 返回 tuple  (x, y, w, h)\n",
    "\treturn (x, y, w, h)\n",
    " \n",
    "def shape_to_np(shape, dtype=\"int\"):\n",
    "\t# 初始化（x，y）坐标的列表\n",
    "\tcoords = np.zeros((shape.num_parts, 2), dtype=dtype)\n",
    " \n",
    "        # 对所有面部标志进行循环并转换\n",
    "        # 关于x（y，y）坐标的2元组\n",
    "\tfor i in range(0, shape.num_parts):\n",
    "\t\tcoords[i] = (shape.part(i).x, shape.part(i).y)\n",
    " \n",
    "\t# 返回（x，y）坐标的列表\n",
    "\treturn coords\n",
    " \n",
    "def visualize_facial_landmarks(image, shape, colors=None, alpha=0.75):\n",
    "        # 创建输入图像的两个副本 (一个用于输入图像)\n",
    "        # 叠加和 (一个用于最终输出图像)\n",
    "\toverlay = image.copy()\n",
    "\toutput = image.copy()\n",
    " \n",
    "        # 如果颜色列表为“否”，则用唯一的方法初始化它。\n",
    "        # 每个脸部标志区域的颜色\n",
    "\tif colors is None:\n",
    "\t\tcolors = [(19, 199, 109), (79, 76, 240), (230, 159, 23),\n",
    "\t\t\t(168, 100, 168), (158, 163, 32),\n",
    "\t\t\t(163, 38, 32), (180, 42, 220)]\n",
    " \n",
    "\t# 在面部标志区域上分别的连线\n",
    "\tfor (i, name) in enumerate(FACIAL_LANDMARKS_IDXS.keys()):\n",
    "\t\t# grab the (x, y)-coordinates associated with the\n",
    "\t\t# face landmark\n",
    "\t\t(j, k) = FACIAL_LANDMARKS_IDXS[name]\n",
    "\t\tpts = shape[j:k]\n",
    " \n",
    "\t\t# 检查是否应该画下颌线\n",
    "\t\tif name == \"jaw\":\n",
    "\t\t\t# 因为 jawline 是一个非封闭的面部区域，\n",
    "                        # 只画出（x，y）坐标之间的直线\n",
    "\t\t\tfor l in range(1, len(pts)):\n",
    "\t\t\t\tptA = tuple(pts[l - 1])\n",
    "\t\t\t\tptB = tuple(pts[l])\n",
    "\t\t\t\tcv2.line(overlay, ptA, ptB, colors[i], 2)\n",
    " \n",
    "\t\t# 处理计算点的凸包\n",
    "\t\t# 并在覆盖图上绘制船体\n",
    "\t\telse:\n",
    "\t\t\thull = cv2.convexHull(pts)\n",
    "\t\t\tcv2.drawContours(overlay, [hull], -1, colors[i], -1)\n",
    " \n",
    "\t# 应用透明覆盖\n",
    "\tcv2.addWeighted(overlay, alpha, output, 1 - alpha, 0, output)\n",
    " \n",
    "\t# 返回输出图像\n",
    "\treturn output\n",
    "\n",
    " \n",
    "#初始化dlib人脸检测（基于HOG），然后创建面部标志预测器\n",
    "detector = dlib.get_frontal_face_detector()\n",
    " \n",
    "predictor = dlib.shape_predictor('./data/shape_predictor_68_face_landmarks.dat')\n",
    " \n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # 一帧一帧捕捉\n",
    "    ret, image = cap.read()\n",
    "    # 我们对帧的操作在这里\n",
    "    image = imutils.resize(image, width=500)  # 调整图片宽度为500\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)#图片调整为灰色\n",
    "    rects = detector(gray, 1)\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = shape_to_np(shape)\n",
    "        ii=visualize_facial_landmarks(image,shape)\n",
    "        cv2.imshow('img',ii)\n",
    "    if len(rects) == 0:\n",
    "\t    cv2.imshow('img',image)\n",
    "    if cv2.waitKey(2) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "眨眼闭嘴检测\n",
    "\n",
    "https://huaweicloud.csdn.net/63808c5edacf622b8df8a83a.html?spm=1001.2101.3001.6650.6&utm_medium=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~activity-6-126468733-blog-80366524.235^v28^pc_relevant_t0_download&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~activity-6-126468733-blog-80366524.235^v28^pc_relevant_t0_download&utm_relevant_index=7\n",
    "'''\n",
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "import dlib\n",
    "import cv2\n",
    "\n",
    "# 眼长宽比例\n",
    "def eye_aspect_ratio(eye):\n",
    "    # (|e1-e5|+|e2-e4|) / (2|e0-e3|)\n",
    "    A = np.linalg.norm(eye[1] - eye[5])\n",
    "    B = np.linalg.norm(eye[2] - eye[4])\n",
    "    C = np.linalg.norm(eye[0] - eye[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "# 嘴长宽比例\n",
    "def mouth_aspect_ratio(mouth):\n",
    "    A = np.linalg.norm(mouth[1] - mouth[7])  # 61, 67\n",
    "    B = np.linalg.norm(mouth[3] - mouth[5])  # 63, 65\n",
    "    C = np.linalg.norm(mouth[0] - mouth[4])  # 60, 64\n",
    "    mar = (A + B) / (2.0 * C)\n",
    "    return mar\n",
    "\n",
    "#  进行活体检测（包含眨眼和张嘴）\n",
    "def liveness_detection():\n",
    "    vs = cv2.VideoCapture(0)  # 调用第一个摄像头的信息\n",
    "\n",
    "    # 眼长宽比例值\n",
    "    EAR_THRESH = 0.15\n",
    "    EAR_CONSEC_FRAMES_MIN = 1\n",
    "    EAR_CONSEC_FRAMES_MAX = 5  # 当EAR小于阈值时，接连多少帧一定发生眨眼动作\n",
    "\n",
    "    # 嘴长宽比例值\n",
    "    MAR_THRESH = 0.2\n",
    "\n",
    "    # 初始化眨眼的连续帧数\n",
    "    blink_counter = 0\n",
    "    # 初始化眨眼次数总数\n",
    "    blink_total = 0\n",
    "    # 初始化张嘴次数\n",
    "    mouth_total = 0\n",
    "    # 初始化张嘴状态为闭嘴\n",
    "    mouth_status_open = 0\n",
    "\n",
    "    print(\"[INFO] loading facial landmark predictor...\")\n",
    "    # 人脸检测器\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    # 特征点检测器\n",
    "    predictor = dlib.shape_predictor(\"data/shape_predictor_68_face_landmarks.dat\")\n",
    "    # 获取左眼的特征点\n",
    "    (lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "    # 获取右眼的特征点\n",
    "    (rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "    # 获取嘴巴特征点\n",
    "    (mStart, mEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"inner_mouth\"]\n",
    "\n",
    "    print(\"[INFO] starting video stream thread...\")\n",
    "    while True:\n",
    "\n",
    "        flag, frame = vs.read()  # 返回一帧的数据\n",
    "        if not flag:\n",
    "            print(\"不支持摄像头\", flag)\n",
    "            break\n",
    "\n",
    "        if frame is not None:\n",
    "            # 图片转换成灰色（去除色彩干扰，让图片识别更准确）\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            rects = detector(gray, 0)  # 人脸检测\n",
    "            # 只能处理一张人脸\n",
    "            if len(rects) == 1:\n",
    "                shape = predictor(gray, rects[0])  # 保存68个特征点坐标的<class 'dlib.dlib.full_object_detection'>对象\n",
    "                shape = face_utils.shape_to_np(shape)  # 将shape转换为numpy数组，数组中每个元素为特征点坐标\n",
    "\n",
    "                left_eye = shape[lStart:lEnd]  # 取出左眼对应的特征点\n",
    "                right_eye = shape[rStart:rEnd]  # 取出右眼对应的特征点\n",
    "                left_ear = eye_aspect_ratio(left_eye)  # 计算左眼EAR\n",
    "                right_ear = eye_aspect_ratio(right_eye)  # 计算右眼EAR\n",
    "                ear = (left_ear + right_ear) / 2.0   # 求左右眼EAR的均值\n",
    "\n",
    "                inner_mouth = shape[mStart:mEnd]  # 取出嘴巴对应的特征点\n",
    "                mar = mouth_aspect_ratio(inner_mouth)  # 求嘴巴mar的均值\n",
    "                left_eye_hull = cv2.convexHull(left_eye)  # 寻找左眼轮廓\n",
    "                right_eye_hull = cv2.convexHull(right_eye)  # 寻找右眼轮廓\n",
    "                mouth_hull = cv2.convexHull(inner_mouth)  # 寻找内嘴巴轮廓\n",
    "                cv2.drawContours(frame, [left_eye_hull], -1, (0, 255, 0), 1)   # 绘制左眼轮廓\n",
    "                cv2.drawContours(frame, [right_eye_hull], -1, (0, 255, 0), 1)  # 绘制右眼轮廓\n",
    "                cv2.drawContours(frame, [mouth_hull], -1, (0, 255, 0), 1)  # 绘制嘴巴轮廓\n",
    "\n",
    "                # EAR低于阈值，有可能发生眨眼，眨眼连续帧数加一次\n",
    "                if ear < EAR_THRESH:\n",
    "                    blink_counter += 1\n",
    "\n",
    "                # EAR高于阈值，判断前面连续闭眼帧数，如果在合理范围内，说明发生眨眼\n",
    "                else:\n",
    "                    # if the eyes were closed for a sufficient number of\n",
    "                    # then increment the total number of blinks\n",
    "                    if EAR_CONSEC_FRAMES_MIN <= blink_counter <= EAR_CONSEC_FRAMES_MAX:\n",
    "                        blink_total += 1\n",
    "                    blink_counter = 0\n",
    "                # 通过张、闭来判断一次张嘴动作\n",
    "                if mar > MAR_THRESH:\n",
    "                     mouth_status_open = 1\n",
    "                else:\n",
    "                    if mouth_status_open:\n",
    "                        mouth_total += 1\n",
    "                    mouth_status_open = 0\n",
    "\n",
    "                cv2.putText(frame, \"Blinks: {}\".format(blink_total), (0, 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                cv2.putText(frame, \"Mouth: {}\".format(mouth_total),\n",
    "                            (130, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                cv2.putText(frame, \"EAR: {:.2f}\".format(ear), (300, 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "                cv2.putText(frame, \"MAR: {:.2f}\".format(mar), (450, 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            elif len(rects) == 0:\n",
    "                cv2.putText(frame, \"No face!\", (0, 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            else:\n",
    "                cv2.putText(frame, \"More than one face!\", (0, 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            cv2.namedWindow(\"Frame\", cv2.WINDOW_NORMAL)\n",
    "            cv2.imshow(\"Frame\", frame)\n",
    "            # 按下q键退出循环（鼠标要点击一下图片使图片获得焦点）\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    cv2.destroyAllWindows()\n",
    "    vs.release()\n",
    "\n",
    "#  调用摄像头进行张嘴眨眼活体检测\n",
    "liveness_detection()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
